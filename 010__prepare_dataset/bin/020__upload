#!/usr/bin/env ruby
ENV['BUNDLE_GEMFILE'] ||= File.expand_path('../../Gemfile', __dir__)
require 'bundler/setup'
Bundler.require(:default)

require 'aws-sdk-s3'
require 'zip'
require 'dotenv'

Dotenv.load(File.expand_path('../../.env', __dir__))

archive_path = File.expand_path("../outputs/#{ENV['AWS_FILE_KEY']}", __dir__)
inventory_filename = "#{File.basename(ENV['AWS_FILE_KEY'], '.zip')}_inventory.json"
inventory_path   = File.expand_path("../outputs/#{inventory_filename}", __dir__)
image_files = Dir.glob(File.expand_path('../inputs/images/*.jpg', __dir__))

puts "PATHS===="
puts archive_path
puts inventory_path
puts image_files


# Delete existing zip file and inventory file
File.delete(archive_path) if File.exist?(archive_path)
File.delete(inventory_path) if File.exist?(inventory_path)

# Zip all images in images directory
Zip::File.open(archive_path, Zip::File::CREATE) do |zipfile|
  image_files.each do |file|
    zipfile.add(File.basename(file), file)
  end
end

# Now read the created ZIP to get accurate byte positions
inventory = { files: [] }
# Analyze ZIP structure
Zip::File.open(archive_path) do |zip|
  zip.each do |entry|
    next if entry.directory?
    
    # Calculate actual byte positions in the ZIP file
    local_header_size = 30 + entry.name.length + entry.extra.length
    start_byte = entry.local_header_offset + local_header_size
    end_byte = start_byte + entry.compressed_size - 1
    
    inventory[:files] << {
      name: entry.name,
      type: File.extname(entry.name),
      compressed_size: entry.compressed_size,
      uncompressed_size: entry.size,
      start_byte: start_byte,
      end_byte: end_byte,
      range: "bytes=#{start_byte}-#{end_byte}",
      compression_method: entry.compression_method
    }
  end
end


File.write(inventory_path, JSON.pretty_generate(inventory))

# Upload zip file to S3
s3 = Aws::S3::Client.new
s3.put_object(
  bucket: ENV['AWS_BUCKET_NAME'],
  key: ENV['AWS_FILE_KEY'],
  body: File.open(archive_path),
  content_type: 'application/zip'
)

# Upload inventory file to S3
s3.put_object(
  bucket: ENV['AWS_BUCKET_NAME'],
  key: inventory_path,
  body: File.open(inventory_path),
  content_type: 'application/x-ndjson'
)